{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "#This outputs single poisson probability\n",
    "def get_poisson_prob(parameter, n):\n",
    "    return (parameter**n / math.factorial(n)) * math.exp(-parameter)\n",
    "\n",
    "#This outputs joint poisson probability\n",
    "def get_joint_prob(request, back, parking):\n",
    "    if parking == 'a':\n",
    "        return get_poisson_prob(3,request)*get_poisson_prob(3,back)\n",
    "    return get_poisson_prob(4,request)*get_poisson_prob(2,back)\n",
    "\n",
    "#Get the action space of given state\n",
    "def get_legal_action(state_a, state_b):\n",
    "    result = []\n",
    "    for action in range(-20,21):\n",
    "        if -state_b <= action <= state_a and action+state_b <= 20 and state_a-action <= 20:\n",
    "            result.append(action)\n",
    "    return result\n",
    "\n",
    "#Help determine the possible combos of request and return in state transition\n",
    "def request_return_boundaries(diff, state, new):\n",
    "    if diff > 0:\n",
    "        return 0, diff, state\n",
    "    return -diff, 0, new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when action = -3 the transition probability is 0.014010000047189993\n",
      "when action = -2 the transition probability is 0.02251703576649734\n",
      "when action = -1 the transition probability is 0.03210495745102386\n",
      "when action = 0 the transition probability is 0.04073020718020566\n",
      "when action = 1 the transition probability is 0.0450966730040062\n",
      "when action = 2 the transition probability is 0.04314269768441976\n",
      "when action = 3 the transition probability is 0.03593556512575768\n"
     ]
    }
   ],
   "source": [
    "#Single instance transition state function\n",
    "def state_transition_prob(new_a, new_b, state_a, state_b, action):\n",
    "    global final_prob_a, final_prob_b\n",
    "    state_a -= action\n",
    "    state_b += action\n",
    "    request_start_a, back_start_a, gap_a = request_return_boundaries(new_a - state_a, state_a, new_a)\n",
    "    request_start_b, back_start_b, gap_b = request_return_boundaries(new_b - state_b, state_b, new_b)\n",
    "    prob_sum_a = sum(get_joint_prob(request_start_a+i, back_start_a+i, 'a') for i in range(gap_a))\n",
    "    prob_sum_b = sum(get_joint_prob(request_start_b+i, back_start_b+i, 'b') for i in range(gap_b))\n",
    "    if new_a == 20:\n",
    "        final_prob_a = (1-sum(get_poisson_prob(3,i) for i in range(request_start_a+gap_a))) * (1-sum(get_poisson_prob(3,j) for j in range(20)))\n",
    "    elif new_a <= 20:\n",
    "        final_prob_a = (1-sum(get_poisson_prob(3,i) for i in range(request_start_a+gap_a))) * get_poisson_prob(3,back_start_a+gap_a)\n",
    "    if new_b == 20:\n",
    "        final_prob_b = (1-sum(get_poisson_prob(4,i) for i in range(request_start_b+gap_b))) * (1-sum(get_poisson_prob(2,j) for j in range(20)))\n",
    "    elif new_b <= 20:\n",
    "        final_prob_b = (1-sum(get_poisson_prob(4,i) for i in range(request_start_b+gap_b))) * get_poisson_prob(2,back_start_b+gap_b)\n",
    "    prob_sum_a += final_prob_a\n",
    "    prob_sum_b += final_prob_b\n",
    "    return prob_sum_a*prob_sum_b\n",
    "\n",
    "\n",
    "#Print all the cases for old state of (3,3)\n",
    "for a in get_legal_action(3,3):\n",
    "    print('when action = {} the transition probability is {}'.format(a, state_transition_prob(3,3,3,3,a)))\n",
    "\n",
    "#Get the complete dictionary of state transition probabilities\n",
    "def all_transition_prob():\n",
    "    dict = {}\n",
    "    for new_a in range(21):\n",
    "        for new_b in range(21):\n",
    "            for state_a in range(21):\n",
    "                for state_b in range(21):\n",
    "                    for action in get_legal_action(state_a,state_b):\n",
    "                        dict['{},{},{},{},{}'.format(new_a,new_b,state_a,state_b,action)] = state_transition_prob(new_a,new_b,state_a,state_b,action)\n",
    "    return dict\n",
    "\n",
    "complete_transition_prob = all_transition_prob()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when action = -3 the reward is 23.492973857591373\n",
      "when action = -2 the reward is 34.47063804839099\n",
      "when action = -1 the reward is 43.70748854919201\n",
      "when action = 0 the reward is 49.79877438147888\n",
      "when action = 1 the reward is 47.695973989080215\n",
      "when action = 2 the reward is 41.39908737199604\n",
      "when action = 3 the reward is 32.04565418537064\n"
     ]
    }
   ],
   "source": [
    "#Single instance reward function\n",
    "def compute_reward(state_a, state_b, action):\n",
    "    state_a -= action\n",
    "    state_b += action\n",
    "    lent_out_a, lent_out_b, sum_prob_a, sum_prob_b = 0, 0, 0, 0\n",
    "    for i in range(state_a+1):\n",
    "        lent_out_a += i*get_poisson_prob(3,i)\n",
    "        sum_prob_a += get_poisson_prob(3,i)\n",
    "    for j in range(state_b+1):\n",
    "        lent_out_b += j*get_poisson_prob(4,j)\n",
    "        sum_prob_b += get_poisson_prob(4,j)\n",
    "    return 10*(lent_out_a + lent_out_b + state_a*(1-sum_prob_a) + state_b*(1-sum_prob_b)) - 2*abs(action)\n",
    "\n",
    "#Print all the cases for state of (3,3)\n",
    "for a in get_legal_action(3,3):\n",
    "    print('when action = {} the reward is {}'.format(a, compute_reward(3,3,a)))\n",
    "\n",
    "#Get the complete dictionary for all rewards\n",
    "def all_reward():\n",
    "    dict = {}\n",
    "    for state_a in range(21):\n",
    "        for state_b in range(21):\n",
    "            for action in get_legal_action(state_a,state_b):\n",
    "                dict['{},{},{}'.format(state_a,state_b,action)] = compute_reward(state_a,state_b,action)\n",
    "    return dict\n",
    "\n",
    "complete_reward = all_reward()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "#Initialize state value dictionary\n",
    "complete_state_value = {}\n",
    "for i in range(21):\n",
    "    for j in range(21):\n",
    "        complete_state_value[f'{i},{j}'] = 0\n",
    "\n",
    "discount_rate = 0.9\n",
    "threshold = 0.001\n",
    "\n",
    "#Performs value iteration and also remembers optimal action along the search\n",
    "#The greedy policy function is combined here since there is little extra cost\n",
    "#Outputs both the optimal value and the optimal action\n",
    "def value_iteration(transition_dict, reward_dict, value_dict):\n",
    "    while True:\n",
    "        action_dict = {}\n",
    "        theta = 0\n",
    "        for state_combo in value_dict.keys():\n",
    "            state_combo = state_combo.split(',')\n",
    "            state_a, state_b = int(state_combo[0]), int(state_combo[1])\n",
    "            #different_action_results = []\n",
    "            best_action, max_value = 0,0\n",
    "            for action in get_legal_action(state_a,state_b):\n",
    "                sum_of_s_prime = 0\n",
    "                for new_a in range(21):\n",
    "                    for new_b in range(21):\n",
    "                        sum_of_s_prime += transition_dict[f'{new_a},{new_b},{state_a},{state_b},{action}'] * value_dict[f'{new_a},{new_b}']\n",
    "                candidate = reward_dict[f'{state_a},{state_b},{action}'] + discount_rate*sum_of_s_prime\n",
    "                #different_action_results.append(candidate)\n",
    "                if candidate > max_value:\n",
    "                    max_value = candidate\n",
    "                    best_action = action\n",
    "            action_dict[f'{state_a},{state_b}'] = best_action\n",
    "            old_value = value_dict[f'{state_a},{state_b}']\n",
    "            #value_dict[f'{state_a},{state_b}'] = max(different_action_results)\n",
    "            value_dict[f'{state_a},{state_b}'] = max_value\n",
    "            theta = max(theta, abs(value_dict[f'{state_a},{state_b}'] - old_value))\n",
    "        if theta < threshold:\n",
    "            return value_dict, action_dict\n",
    "\n",
    "\n",
    "optimal_state_value, optimal_action = value_iteration(complete_transition_prob, complete_reward, complete_state_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.9495217329611\n"
     ]
    }
   ],
   "source": [
    "print(optimal_state_value['3,3'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Finding the optimal action\n",
    "#the same stuff is already implemented in value iteration above\n",
    "#this displays how to do greedy policy separately\n",
    "def determine_greedy_policy(transition_dict, reward_dict, value_dict):\n",
    "    policy_dict = {}\n",
    "    for state_combo in value_dict.keys():\n",
    "        state_combo = state_combo.split(',')\n",
    "        state_a, state_b = int(state_combo[0]), int(state_combo[1])\n",
    "        best_result, best_action = 0,0\n",
    "        for action in get_legal_action(state_a,state_b):\n",
    "            sum_of_s_prime = 0\n",
    "            for new_a in range(21):\n",
    "                for new_b in range(21):\n",
    "                    sum_of_s_prime += transition_dict[f'{new_a},{new_b},{state_a},{state_b},{action}'] * value_dict[f'{new_a},{new_b}']\n",
    "            candidate = reward_dict[f'{state_a},{state_b},{action}'] + sum_of_s_prime*discount_rate\n",
    "            if candidate > best_result:\n",
    "                best_result = candidate\n",
    "                best_action = min(action,5)\n",
    "        policy_dict[f'{state_a},{state_b}'] = best_action\n",
    "    return policy_dict\n",
    "\n",
    "greedy_policy = determine_greedy_policy(complete_transition_prob, complete_reward, optimal_state_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 369,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action to take at state (0,3) is   0\n",
      "The action to take at state (1,3) is   0\n",
      "The action to take at state (2,3) is   0\n",
      "The action to take at state (3,3) is   0\n",
      "The action to take at state (4,3) is   0\n",
      "The action to take at state (5,3) is   0\n",
      "The action to take at state (6,3) is   1\n",
      "The action to take at state (7,3) is   1\n",
      "The action to take at state (8,3) is   2\n",
      "The action to take at state (9,3) is   2\n",
      "The action to take at state (10,3) is   3\n",
      "The action to take at state (11,3) is   3\n",
      "The action to take at state (12,3) is   3\n",
      "The action to take at state (13,3) is   3\n",
      "The action to take at state (14,3) is   4\n",
      "The action to take at state (15,3) is   4\n",
      "The action to take at state (16,3) is   5\n",
      "The action to take at state (17,3) is   5\n",
      "The action to take at state (18,3) is   5\n",
      "The action to take at state (19,3) is   5\n",
      "The action to take at state (20,3) is   5\n"
     ]
    }
   ],
   "source": [
    "for i in range(21):\n",
    "    print(f'The action to take at state ({i},3) is  ', greedy_policy[f'{i},3'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}